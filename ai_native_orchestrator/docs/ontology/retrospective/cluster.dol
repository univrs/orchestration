# Cluster Management Domain Ontology
# Retrospective analysis of cluster_manager module
# Generated from: cluster_manager_interface/, cluster_manager/

@domain cluster
@version 1.0.0

# =============================================================================
# GENES - Core data structures for cluster membership
# =============================================================================

gene ClusterNode {
  description: "Node as seen by cluster membership system"
  properties {
    id: NodeId                    # UUID identifier
    name: String                  # Human-readable name
    address: SocketAddr           # Gossip protocol address
    generation: u64               # Incarnation number for disambiguation
    state: MembershipState        # Alive, Suspect, Dead, Left
    metadata: HashMap<String, String>  # Custom node metadata
    heartbeat_seq: u64            # Monotonic heartbeat counter
    last_seen: DateTime           # Last successful communication
  }
}

gene MembershipState {
  description: "Node membership lifecycle state"
  variants {
    Alive     # Node is healthy and responsive
    Suspect   # Node missed heartbeats, under investigation
    Dead      # Node confirmed unreachable
    Left      # Node gracefully departed cluster
  }
}

gene ClusterEvent {
  description: "Membership change notification"
  variants {
    NodeAdded(NodeInfo)       # New node joined cluster
    NodeRemoved(NodeId)       # Node left or was removed
    NodeUpdated(NodeInfo)     # Node metadata changed
    LeaderElected(NodeId)     # New leader selected (if applicable)
    PartitionDetected         # Network partition suspected
    PartitionHealed           # Partition resolved
  }
}

gene GossipMessage {
  description: "Inter-node gossip protocol message"
  properties {
    sender: NodeId
    sequence: u64                 # Message ordering
    payload: GossipPayload
    timestamp: DateTime
  }
}

gene GossipPayload {
  description: "Gossip message content types"
  variants {
    Ping                          # Liveness probe
    PingAck                       # Probe acknowledgment
    IndirectPing(NodeId)          # Probe via intermediary
    Sync(MembershipList)          # Full state synchronization
    SyncDelta(Vec<MembershipDelta>)  # Incremental update
    UserEvent(Vec<u8>)            # Application-level event
  }
}

gene FailureDetectorState {
  description: "Phi-accrual failure detector state"
  properties {
    node_id: NodeId
    heartbeat_history: CircularBuffer<Duration>  # Recent inter-arrival times
    last_heartbeat: DateTime
    phi_value: f64                # Suspicion level (higher = more suspicious)
    threshold: f64                # Phi threshold for failure declaration
  }
}

gene ClusterConfig {
  description: "Cluster membership configuration"
  properties {
    cluster_id: String            # Unique cluster identifier
    node_id: NodeId               # This node's identity
    listen_addr: SocketAddr       # Gossip listen address
    seed_nodes: Vec<SocketAddr>   # Bootstrap nodes
    gossip_interval: Duration     # Gossip frequency
    failure_timeout: Duration     # Time before node declared dead
    suspicion_mult: u32           # Suspicion period multiplier
    probe_interval: Duration      # Direct probe frequency
    indirect_probes: u32          # Number of indirect probes
  }
}

# =============================================================================
# TRAITS - Cluster management behavioral interface
# =============================================================================

trait ClusterManager {
  description: "Core cluster membership management"

  # Lifecycle
  async fn initialize(config: ClusterConfig) -> Result<()>
  async fn shutdown() -> Result<()>
  async fn join(seed_nodes: Vec<SocketAddr>) -> Result<()>
  async fn leave() -> Result<()>

  # Node discovery
  async fn get_node(id: NodeId) -> Result<Option<ClusterNode>>
  async fn list_nodes() -> Result<Vec<ClusterNode>>
  async fn get_live_nodes() -> Result<Vec<ClusterNode>>

  # Event subscription
  fn subscribe_to_events() -> broadcast::Receiver<ClusterEvent>
}

trait GossipProtocol {
  description: "Gossip-based membership protocol"

  async fn send_gossip(target: SocketAddr, msg: GossipMessage) -> Result<()>
  async fn receive_gossip() -> Result<GossipMessage>
  async fn process_gossip(msg: GossipMessage) -> Result<()>

  fn select_gossip_targets(count: usize) -> Vec<NodeId>
  fn merge_membership(remote: MembershipList) -> MembershipList
}

trait FailureDetector {
  description: "Node failure detection interface"

  fn record_heartbeat(node_id: NodeId, timestamp: DateTime)
  fn get_phi(node_id: NodeId) -> f64
  fn is_suspected(node_id: NodeId) -> bool
  fn is_dead(node_id: NodeId) -> bool
  fn get_suspected_nodes() -> Vec<NodeId>
}

trait LeaderElection {
  description: "Distributed leader election (optional)"

  async fn start_election() -> Result<()>
  async fn get_leader() -> Option<NodeId>
  fn is_leader() -> bool
  async fn step_down() -> Result<()>
}

# =============================================================================
# CONSTRAINTS - Cluster behavior rules
# =============================================================================

constraint MembershipTransitions {
  description: "Valid membership state transitions"
  rules {
    Alive -> [Suspect, Left]
    Suspect -> [Alive, Dead]
    Dead -> [Alive]  # Rejoin with new generation
    Left -> [Alive]  # Rejoin
  }
}

constraint FailureDetectionBounds {
  description: "Failure detection timing constraints"
  rules {
    phi_threshold in range [4.0, 16.0]  # Reasonable suspicion thresholds
    gossip_interval in range [100ms, 5s]
    failure_timeout >= gossip_interval * 3
    suspicion_period = failure_timeout * suspicion_mult
  }
}

constraint GossipConvergence {
  description: "Gossip protocol convergence guarantees"
  rules {
    membership_converges_within O(log(N)) gossip_rounds
    event_propagates_to_all_nodes_within bounded_time
    no_permanent_inconsistency assuming partial_synchrony
  }
}

constraint NetworkPartitionHandling {
  description: "Split-brain prevention"
  rules {
    minority_partition cannot_elect_leader
    rejoin requires generation_increment
    stale_messages ignored_via sequence_numbers
  }
}

constraint SeedNodeRequirements {
  description: "Bootstrap node requirements"
  rules {
    seed_nodes.len() >= 1 for_cluster_formation
    at_least_one_seed_must_be_reachable
    self_can_be_seed_for single_node_cluster
  }
}

# =============================================================================
# SYSTEMS - Cluster management workflows
# =============================================================================

system GossipDisseminator {
  description: "Manages gossip-based state dissemination"
  uses [GossipProtocol, ClusterManager]

  workflow gossip_round {
    1. Select k random nodes (fanout)
    2. Prepare gossip message with local state
    3. Send gossip to selected nodes concurrently
    4. Receive and merge remote state
    5. Update local membership view
    6. Schedule next round after gossip_interval
  }

  workflow handle_incoming_gossip(msg: GossipMessage) {
    1. Validate message (sequence, sender known)
    2. Extract membership information
    3. Compare with local view
    4. Merge using CRDT semantics
    5. Emit ClusterEvents for changes
    6. Optionally respond with local state
  }
}

system PhiAccrualFailureDetector {
  description: "Adaptive failure detection using phi-accrual"
  uses [FailureDetector]

  state {
    heartbeat_windows: HashMap<NodeId, SlidingWindow<Duration>>
    phi_calculator: PhiCalculator
  }

  workflow monitor_node(node_id: NodeId) {
    1. Receive heartbeat
    2. Calculate inter-arrival time
    3. Update sliding window
    4. Compute new phi value
    5. If phi > threshold, mark Suspect
    6. If Suspect persists, mark Dead
  }

  formula phi_calculation {
    # Phi = -log10(P_later(t_now - t_last))
    # P_later uses normal distribution of inter-arrival times
    mean = window.mean()
    variance = window.variance()
    phi = -log10(1 - F(elapsed_time, mean, sqrt(variance)))
  }
}

system ClusterBootstrapper {
  description: "Handles cluster join and bootstrap"
  uses [ClusterManager, GossipProtocol]

  workflow join_cluster {
    1. Generate or load NodeId
    2. Set generation = previous_generation + 1
    3. Contact seed nodes
    4. Perform full state sync
    5. Start gossip protocol
    6. Announce self to cluster
    7. Begin failure detection
  }

  workflow graceful_leave {
    1. Stop accepting new work
    2. Broadcast Leave intention
    3. Wait for acknowledgments (with timeout)
    4. Stop gossip protocol
    5. Close connections
  }
}

system EventBroadcaster {
  description: "Cluster event notification system"
  uses [ClusterManager]

  channels {
    events: broadcast::Sender<ClusterEvent>
  }

  workflow broadcast_change(event: ClusterEvent) {
    1. Log event for audit
    2. Broadcast to all local subscribers
    3. If user_event, include in next gossip
    4. Trigger registered callbacks
  }
}

# =============================================================================
# IMPLEMENTATIONS - Concrete cluster backends
# =============================================================================

implementation ChitchatManager of ClusterManager + GossipProtocol {
  description: "Cluster management using Chitchat gossip library"

  dependencies {
    chitchat: "0.x"               # Quickwit's gossip library
  }

  characteristics {
    protocol: SWIM-based gossip
    failure_detection: phi_accrual
    state_sync: crdt_delta_based
    transport: UDP + TCP fallback
  }

  configuration {
    cluster_id: from_config
    listen_addr: from_config
    seed_nodes: from_config or dns_discovery
    gossip_interval: 200ms
    failure_detector_threshold: 8.0
    max_gossip_message_size: 65535 bytes
  }

  key_value_store {
    # Chitchat provides distributed KV store
    keys: versioned with timestamps
    conflict_resolution: last_writer_wins
    propagation: eventual_via_gossip
  }
}

implementation MockClusterManager of ClusterManager {
  description: "In-memory cluster manager for testing"

  storage {
    nodes: HashMap<NodeId, ClusterNode>
    events: Vec<ClusterEvent>
  }

  characteristics {
    synchronous: true
    deterministic: true
    no_network: true
  }
}
